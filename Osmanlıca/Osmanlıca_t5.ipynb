{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "son_t5_machinetranslation.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/inspectorgadgetteknofest/inspector-gadget-acikhack2021/blob/main/Osmanl%C4%B1ca/Osmanl%C4%B1ca_t5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DqsJRZkpbVK6"
      },
      "source": [
        "## Kütüphanelerin Import Edilmesi:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z_TBM0OAfQS0"
      },
      "source": [
        "# Drive'ı initialize etme\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GllzP7GT4-o-"
      },
      "source": [
        "# Bleu score hesaplamak için\n",
        "!pip install sacrebleu"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PPs_k3YIe4tn"
      },
      "source": [
        "!pip install transformers\n",
        "!pip install simpletransformers\n",
        "# !pip install wandb -q"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GjmhQCh83kEE"
      },
      "source": [
        "# Veriyi çekme ve ön işleme için:\n",
        "import pandas as pd\n",
        "\n",
        "# Veriyi train2e hazırlama ve train etme için\n",
        "from sklearn.model_selection import train_test_split\n",
        "import logging\n",
        "from simpletransformers.t5 import T5Model, T5Args\n",
        "\n",
        "# Predict ve Bleu Score hesaplamak için \n",
        "import sacrebleu"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jQnpgheZzVST"
      },
      "source": [
        "## 2. Veri Seti\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qB36erId3SG8"
      },
      "source": [
        "# Verisetinin okunması:\n",
        "data_path = \"oe_tr.xlsx\" #@param {type:\"string\"}\n",
        "df = pd.read_excel(data_path)\n",
        "\n",
        "# Veri setinin incelenmesi\n",
        "df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bt-7IoYa3UXx"
      },
      "source": [
        "## Osmanlıca-Türkçe mi Türkçe-Osmanlıca mı?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L5dQsIM_cAcV"
      },
      "source": [
        "Kullanılacak çeviri işlemine göre ikisinden biri çalıştırılmalıdır."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LY4ytgTI3Fuh"
      },
      "source": [
        "Osmanlıca --> Türkçe ise:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pNK9LSwy3JNO"
      },
      "source": [
        "# Sütun adlarının değiştirilmesi\n",
        "df.columns = ['input_text','target_text']\n",
        "\n",
        "# İstenilen dile çevirilirken 'translate' kelimesi eklendi.\n",
        "df.target_text = 'translate: ' + df.target_text\n",
        "\n",
        "# İlk 5 veriyi görelim:\n",
        "print(df.head())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N4OKm6Yh3JiK"
      },
      "source": [
        "Türkçe --> Osmanlıca ise:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XcESdYOT3U-c"
      },
      "source": [
        "# Sütun adlarının değiştirilmesi:\n",
        "df.columns = ['target_text','input_text']\n",
        "\n",
        "# İstenilen dile çevirilirken 'translate' kelimesi eklendi.\n",
        "df.target_text = 'translate: ' + df.target_text\n",
        "\n",
        "# İlk 5 veriyi görelim:\n",
        "print(df.head())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JjpnxWxQ3W-q"
      },
      "source": [
        "# Boş bir sütun ekleyip adını 'prefix' verelim. Bu sütun modele birden fazla işlem \n",
        "# tanımlandığı durumlarda kullanılır. Bizde tek bir işlem olacağı için bu sütunun\n",
        "# büyük bir anlamı olmayacak ama yine de koyalım : \n",
        "df[\"prefix\"] = \"\"\n",
        "df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DWERDpuCyqiH"
      },
      "source": [
        "# Train test ayrımını yapalım. (Bunu yaparken 0.2 oranında ayıralım)\n",
        "train, test = train_test_split(df, test_size = 0.20, random_state = 42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3E1zDc48wX0C"
      },
      "source": [
        "# train veri setine göz atalım:\n",
        "train"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XHMjiba_wZMq"
      },
      "source": [
        "# test veri setine göz atalım:\n",
        "test"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_FeMzKs-zWE7"
      },
      "source": [
        "logging.basicConfig(level=logging.INFO)\n",
        "transformers_logger = logging.getLogger(\"transformers\")\n",
        "transformers_logger.setLevel(logging.WARNING)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q2DE-1yuX3d5"
      },
      "source": [
        "# Modelin kaydedileceği path bilgisi :\n",
        "OUTPUT_DIR = \"osmanl\\u0131ca-tu\\u0308rkc\\u0327e/model\" #@param {type:\"string\"}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lo_EsvBBzWne"
      },
      "source": [
        "model_args = T5Args()\n",
        "model_args.max_seq_length = 256\n",
        "model_args.train_batch_size = 4\n",
        "model_args.eval_batch_size = 4\n",
        "model_args.num_train_epochs = 3\n",
        "model_args.evaluate_during_training = False\n",
        "model_args.use_multiprocessing = False\n",
        "model_args.fp16 = False\n",
        "model_args.save_steps = 5000\n",
        "model_args.save_eval_checkpoints = False\n",
        "model_args.save_model_every_epoch = True\n",
        "model_args.output_dir = OUTPUT_DIR\n",
        "model_args.no_cache = True\n",
        "model_args.reprocess_input_data = True\n",
        "model_args.overwrite_output_dir = True\n",
        "model_args.num_return_sequences = 1\n",
        "#model_args.wandb_project = \"MT5 mixed tasks\"\n",
        "\n",
        "model = T5Model(\"mt5\", \"google/mt5-base\", args=model_args)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "PWCyeqyUz5G9"
      },
      "source": [
        "# Model eğitimi:\n",
        "model.train_model(train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "39sJ0uQP3QNk"
      },
      "source": [
        "# Modelin tahmin ettirilmesi:\n",
        "model.predict([\"Atılmış\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4jo4DF1O4zeh"
      },
      "source": [
        "## Predict ve Evaluation Kısmı:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vHQDpGXw4z1c"
      },
      "source": [
        "logging.basicConfig(level=logging.INFO)\n",
        "transformers_logger = logging.getLogger(\"transformers\")\n",
        "transformers_logger.setLevel(logging.WARNING)\n",
        "\n",
        "\n",
        "model_args = T5Args()\n",
        "model_args.max_length = 256\n",
        "model_args.length_penalty = 1\n",
        "model_args.num_beams = 10\n",
        "\n",
        "model = T5Model(\"mt5\", \"./checkpoint-5000\", args=model_args)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TdOCbdF447fh"
      },
      "source": [
        "# Birbirleriyle karşılaştırmak için tahminleri ve doğru değerleri bir listeye atalım:\n",
        "eval = test[\"input_text\"].to_list()\n",
        "true = test[\"target_text\"].to_list()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vh3OwarF5O7I"
      },
      "source": [
        "# Tahminleri bir yerde toplayalım:\n",
        "preds = model.predict(eval)\n",
        "\n",
        "# bleu score'u ölçmek için: \n",
        "bleu = sacrebleu.corpus_bleu(preds, true)\n",
        "print(\"--------------------------\")\n",
        "print(f\"Türkçe'den Osmanlıca'ya: \" {bleu.score})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-3cYQVA8w9Ez"
      },
      "source": [
        "## Eğitimin Sonuçları:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tK7uYjrbrckv"
      },
      "source": [
        "# Eğitimin bleu score'unun hesaplanması:\n",
        "bleu = sacrebleu.corpus_bleu(preds, true)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7-b02zHpuLrC"
      },
      "source": [
        "# bleu score'unun ekrana bastırılması:\n",
        "bleu.score"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6MxxuDdRUUZp"
      },
      "source": [
        "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"./checkpoint-5000\")\n",
        "model = AutoModelForSeq2SeqLM.from_pretrained(\"/content/drive/MyDrive/Açık Hack Yarışma/osmanlıca-türkçe/model/checkpoint-5000\").cpu()\n",
        "def translate(text):\n",
        "  translated = model.generate(**tokenizer(text, return_tensors=\"pt\", padding=True))\n",
        "  translation= [tokenizer.decode(t, skip_special_tokens=True) for t in translated]\n",
        "  return translation\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VF3TJ1pgPGrT"
      },
      "source": [
        "def translate_text(estimator, subtokenizer, txt):\n",
        "  \"\"\"Tek bir text i translate etmek için\"\"\"\n",
        "  encoded_txt = _encode_and_add_eos(txt, subtokenizer)\n",
        "\n",
        "  def input_fn():\n",
        "    ds = tf.data.Dataset.from_tensors(encoded_txt)\n",
        "    ds = ds.batch(_DECODE_BATCH_SIZE)\n",
        "    return ds\n",
        "\n",
        "  predictions = estimator.predict(input_fn)\n",
        "  translation = next(predictions)[\"outputs\"]\n",
        "  translation = _trim_and_decode(translation, subtokenizer)\n",
        "  tf.logging.info(\"Bunun çevirisi \\\"%s\\\": \\\"%s\\\"\" % (txt, translation))\n",
        "  return translation"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qhbS1OfcM7Na"
      },
      "source": [
        "import tensorflow as tf\n",
        "import FastPredict\n",
        "\n",
        "class FastPredict:\n",
        "\n",
        "    def __init__(self, estimator, input_fn):\n",
        "        self.estimator = estimator\n",
        "        self.first_run = True\n",
        "        self.closed = False\n",
        "        self.input_fn = input_fn\n",
        "\n",
        "    def _create_generator(self):\n",
        "        while not self.closed:\n",
        "            yield self.next_features\n",
        "\n",
        "    def predict(self, feature_batch):\n",
        "        \n",
        "        self.next_features = feature_batch\n",
        "        if self.first_run:\n",
        "            self.batch_size = len(feature_batch)\n",
        "            self.predictions = self.estimator.predict(\n",
        "                input_fn=self.input_fn(self._create_generator))\n",
        "            self.first_run = False\n",
        "        elif self.batch_size != len(feature_batch):\n",
        "            raise ValueError(\"Tüm batchler eşit uzunlukta olmalıdır. İlk-batch:\" + str(self.batch_size) + \" Bu-batch:\" + str(len(feature_batch)))\n",
        "\n",
        "        results = []\n",
        "        for _ in range(self.batch_size):\n",
        "            results.append(next(self.predictions))\n",
        "        return results\n",
        "\n",
        "    def close(self):\n",
        "        self.closed = True\n",
        "        try:\n",
        "            next(self.predictions)\n",
        "        except:\n",
        "            print(\"Exception in predict. This is probably OK\")\n",
        "\n",
        "\n",
        "def example_input_fn(generator):\n",
        "    \n",
        "\n",
        "    def _inner_input_fn():\n",
        "        dataset = tf.data.Dataset().from_generator(generator, output_types=(tf.float32)).batch(1)\n",
        "        iterator = dataset.make_one_shot_iterator()\n",
        "        features = iterator.get_next()\n",
        "        return {'x': features}\n",
        "\n",
        "    return _inner_input_fn\n",
        "classifier = FastPredict(learn.Estimator(model_fn=model_params.model_fn, model_dir=model_params.model_dir), my_input_fn)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}